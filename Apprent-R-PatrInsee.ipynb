{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "\n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" style=\"float:right; max-width: 250px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Scénario d'Apprentissage Statistique](https://github.com/wikistat/Apprentissage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enquête INSEE sur le Patrimoine des Français: score d'appétence avec  <a href=\"https://cran.r-project.org/\"><img src=\"https://cran.r-project.org/Rlogo.svg\" style=\"max-width: 40px; display: inline\" alt=\"R\"/></a> pour l'assurance vie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Résumé\n",
    "Après avoir réalisé le premier [objectif de segmentation](https://github.com/wikistat/Exploration/blob/master/Exploration/Explo-R-PatrInsee.ipynb) ou profilage des types de comportement des français vis à vis de leur patrimoine, l'objectif, est de contruire un outil classique en GRr (gestion de la relation client). La plupart des méthodes sont abordées et  comparées [régression logistique](http://wikistat.fr/pdf/st-m-app-rlogit.pdf), [analyse discriminante](http://wikistat.fr/pdf/st-m-app-add.pdf), [arbre de discrimination](http://wikistat.fr/pdf/st-m-app-cart.pdf), [agrégation de modèles](http://wikistat.fr/pdf/st-m-app-agreg.pdf), [SVM](http://wikistat.fr/pdf/st-m-app-svm.pdf). Les estimations des [erreurs de prévision](http://wikistat.fr/pdf/st-m-app-risque-estim.pdf) et les courbes [ROC](http://wikistat.fr/pdf/st-m-app-risque-estim.pdf) sont comparées à la suite du tirage itératif d'un ensemble d'échantillons tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "### Objectif\n",
    "Le travail proposé vient compléter le cours sur l'apprentissage statistique. Son objectif est double : \n",
    "1. illustrer l'emploi de chacune des méthodes du cours sur un exemple en vraie grandeur mais relativement simple, \n",
    "2.  mettre en \\oe uvre une procédure systématique de comparaison des erreurs de prévisions ainsi que des courbes ROC estimées sur un échantillon test par les différentes méthodes.\n",
    "\n",
    "Il  s'intéresse à un jeu de données décrivant le patrimoine des français (enquête INSEE)  et se propose de comparer plusieurs méthodes de modélisation (régression logistique, réseaux de neurones, arbres de décision, agrégation de modèles) pour aborder un problème très classique en Gestion de la Relation Client (GRC / CRM) : construire un score d'appétence. Il s'agit du score d'appétence pour l'assurance vie mais ce pourrait être un score d'attrition (churn) d'un opérateur téléphonique  ou encore un score de défaillance d'un emprunteur ou de faillite d'une entreprise ; les outils de modélisation sont les mêmes et sont très largement utilisés dans tout le secteur tertiaire pour l'aide à la décision.\n",
    "\n",
    "\n",
    "### Les données\n",
    "#### Origine\n",
    "Les données sont publiques et  accessibles sur le site de l'INSEE. Elles sont issues d'une enquête \"Patrimoine\" réalisée en 2003-2004 qui faisait suite à des enquêtes \"Actifs financiers\" de 1986 et 1992. L'enquête Patrimoine visait une connaissance globale du patrimoine des ménages ainsi que de ses principales composantes. Elle recense tous les différents types d'actifs financiers, immobiliers et professionnels détenus par les individus ainsi que les différents types d'emprunts (immobilier, à la consommation, achat voiture, biens professionnels, ...). Outre la connaissance de souscriptions à différents types de produits, l'enquête interroge aussi les individus sur leur motivation de détention permettant ainsi d'appréhender le comportement patrimonial des ménages.\n",
    "\n",
    "**Attention**: La structure des données est relativement complexe, il est vivement recommandé d'avoir réalisé le scénario précédent d'[exploration des données](https://github.com/wikistat/Exploration/tree/master/Patrim-Insee), où elles sont précisément décrites, avant de se lancer dans le travail de modélisation qui va suivre. \n",
    "\n",
    "#### Variables\n",
    "Finalement, à l'issue ce travail préliminaire et d'exploration, l'étude présente débute avec une base contenant 11887 individus décrits par 36 variables dont 2 sont redondantes (qualitatives et quantitatives) :\n",
    "- 2 quantitatives : `Age, Nbenf`\n",
    "- 34 qualitatives : ` Asvi, Sexe, Tage, Couple, Vmatri, Diplome, Ocupa, Work, statut, Herit, Pere, Mere, Gparp, gparm, Jgrav, Livep, Epalo, fepsal, vmob, livdf, pel, cel, qpep, asdecv, Retrai, Qpea, Urbani, Zeat, Nbenfq, Iogoc, terre, dette, bdetre, hdetvo`\n",
    "\n",
    "définies dans le Tableau ci-dessous. \n",
    "\n",
    "Une première conclusion de l'étude précédente montre qu'il aurait été sûrement beaucoup plus efficace, à même coût, d'interroger beaucoup moins de monde avec beaucoup moins de questions mais en prenant le temps d'obtenir des réponses précises à l'ensemble des questions ! C'est malheureusement un comportement excessivement répandu dans beaucoup de disciplines, des Sciences humaines à la Biologie, de viser un niveau de détail beaucoup trop fin au regard de la précision des données ou de la taille de l'échantillon. Ainsi, les variables décrivant les ressources et le patrimoine n'ont même pas été prises en compte car elles présentent beaucoup trop de données manquantes : 90 \\% pour le patrimoine financier, 60 \\% pour l'autre ; même chose pour les variables relatives aux petits enfants. C'est la faiblesse majeure de cette enquête ; trop d'informations tue l'information. \n",
    "\n",
    "L'absence de ces variables va pénaliser sévèrement la qualité des modèles mais c'est une réalité à laquelle il est nécessaire de se confronter.\n",
    "\n",
    "*Tableau: Identifiant, signification des variables retenues et liste des modalités; les identifiants des variables et modalités ont été choisis courts et mnémotechniques pour simplifier et aider l'interprétation des graphiques.*\n",
    "\n",
    "**Identif**. | **Libellé** |**Modalités**\n",
    "            -|-           -|-\n",
    "Asvi | Possession ou non assurance vie | AsO, AsN\n",
    "AsviR | idem | 1, 0\n",
    "Sexe | Genre | Sh, Sf\n",
    "Age | Age | Quantitatif\n",
    "Tage | Tranches d'âge | T10 à T90\n",
    "Couple | Vie ou non en couple | CouO CouN\n",
    "Vmatri | Statut matrimonial  | Vcel Vmar Vveu Vdiv\n",
    "Nation | Nationalité  | Nfra Nnat Netr\n",
    "Diplome | Niveau de diplôme  | Dsan, Dcep, Dtec (cap, bep), Dbepc, Dbact Dbacg, Db+2, Db+5\n",
    "Occupa | Type d'occupation  | Oact, Oina (foyer, chom, other), Oret\n",
    "Work | Niveau professionnel  | WctA (cadre, catA), WctB (agent, catB, tech), Wemp, WctC (osp, ouv) \n",
    "statut | Statut professionnel  | spri, spub, sind\n",
    "Herit | Bénéfice ou non d'un héritage  | HerO, HerN\n",
    "Pere | Présence ou non du père  | PerO PerN PerI\n",
    "Mere | Présence ou non de la mère  | MerO, MerN MerI\n",
    "Gparp | Grands parents paternels  | GppO GppN GppI\n",
    "gparm | Grands parents maternels  | gpmO gpmN gpmI\n",
    "Jgrav | Evènement grave dans la jeunesse  | JgvO  JgvN \n",
    "Livep | Livret d'épargne  | LivO LivN\n",
    "Epalo | Epargne logement  | EplO EplN\n",
    "qpep | Plan d'épargne populaire  | qppO qppN\n",
    "vmob | Valeurs mobilières  | vmoO vmoN\n",
    "asdecv | Assurance décès volontaire  | asdO asdN\n",
    "Retrait | Epargne retraite   | RepO RepN\n",
    "livdf | Livret défiscalisé   | ldfO, ldfN\n",
    "pel | Plan épargne logement   | pelO, pelN\n",
    "cel | Compte épargne logement  | celO, celN\n",
    "xcapi |Bons de capitalisation  | xcpO xcpN\n",
    "fepsal | Epargne salarial ou stock options  | fesO fesN\n",
    "Qpea | Plan épargne action  | QpeO QpeN\n",
    "Urbani | Niveau d'urbanisation  | U1 à U5\n",
    "Zeat | Région de résidence  | Zso Zpar Zoue Zne Zmed Zidf Zcen\n",
    "Nbenf | Nombre d'enfants  | Quantitatif\n",
    "Nbenfq | Nombre d'enfants  | Nbe0, Nbe1, Nbe2, Nb>3\n",
    "Iogoc | Type d'occupation du logement   | Iloc, Iprp (usufruit)\n",
    "terre | Possession de terres  | terO terN\n",
    "dette | Dettes ou emprunts  | detO detN\n",
    "bdetre | Emprunt achat maison  | bemO bemN\n",
    "hdetvo  | Emprunt voiture  | hevO hevN\n",
    "\n",
    "\n",
    "**Répondre aux questions en s'aidant des résultats des exécutions**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratégie de construction d'un score\n",
    "L'objectif est la recherche d'un meilleur modèle de prévision de la probabilité de possession d'un contrat d'assurance vie. Meilleur au sens de la minimisation d'une erreur de prévision estimée sur une partie tes de l'échantillon. \n",
    "\n",
    "La démarche mise en \\oe uvre enchaîne les étapes classiques suivantes :\n",
    "1. Après l'étape descriptive uni ou multidimensionnelle visant à repérer les incohérences, les variables non significatives, les individus non concernés\\ldots et à étudier les structures des données, procéder à un tirage aléatoire d'un échantillon {\\em test} qui ne sera utilisé que lors de la {\\em dernière étape}.\n",
    "2. Sur la partie restante qui sera  découpée en échantillon d'\\em{apprentissage} (des paramètres du modèle) et échantillon de *validation* (pour estimation sans biais du taux de mauvais classés), optimiser les choix afférents à chacune des méthodes de discrimination :\n",
    "    - variables et interactions à prendre en compte dans la régression logistique,\n",
    "    - nombre de n\\oe uds dans l'arbre de classification,\n",
    "    - architecture (nombre de couches, de neurones par couche, fonctions de transferts, nombre de cycles...) du perceptron.\n",
    "    - algorithme d'agrégation de modèles\n",
    "    - éventuellement d'autres méthodes...\n",
    "3. En cas d'échantillon petit face au nombre des variables il est recommandé d'itérer la procédure de découpage par validation croisée, ce n'est réellement le cas de ces données mais, afin d'estimer les variances d'erreur de classement ou leurs distributions, la procédure est itérée.\n",
    "4. Comparaison finale des qualités de prévision et des courbes ROC sur la base du taux de mal classés pour le seul échantillon test qui est resté à l'écart de tout effort ou acharnement pour l'optimisation des modèles.\n",
    "\n",
    "** Attention** ne pas \"tricher\" en modifiant le modèle obtenu lors de l'étape précédente afin d'améliorer le résultat sur l'échantillon test !\n",
    "\n",
    "\n",
    "Deux stratégies ou approches sont mises en \\oe uvre : \n",
    "- *Artisanale* à l'aide des méthodes les plus utilisées dans le contexte de la GRC: régression logistique très majoritaire et arbres de décision; avec l'idée de chercher à interpréter les modèles.\n",
    "- *Industrielle* comparaison systématique et automatique de plusieurs modèles, dont réseaux de neurones, agrégation..., à l'aide du package `caret`; la qualité de prévision prévaut.\n",
    "\n",
    "## Approche artisanale\n",
    "### Lecture des données\n",
    "Celles-ci sont dans un fichier chargé en même temps que ce calepin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insee = read.csv(\"patriminsee.csv\")\n",
    "insee=insee[,-c(2,38)]\n",
    "summary(insee)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition de l'échantillon\n",
    "Il s'agit d'isoler un *échantillon test* qui ne servira qu'à la seule comparaison des méthodes mais pas à l'estimation ni au choix de modèle inhérent à chacune d'elles. La séparation entre échantillon d'apprentissage et échantillon test se fait de la façon ci-dessous après initialisation du générateur de nombres aléatoires afin d'en contrôler la séquence pour d'autres exécutions. Il est vivement recommandé de conserver dans un fichier la liste des commandes R exécutées. Cela permettra ainsi de les ré-exécuter facilement pour une autre valeur de l'initialisation du générateur de nombres aléatoires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx=... # Initialiser xxx par un entier de votre choix\n",
    "set.seed(xxx) \n",
    "npop=nrow(insee)\n",
    "# tirage de 3000 indices sans remise\n",
    "testi=sample(1:npop,3000)\n",
    "#Liste des indices restant qui n'ont pas été tirés\n",
    "appri=setdiff(1:npop,testi) \n",
    "# Extraction échantillon d'apprentissage\n",
    "inseeAppt=insee[appri,]  \n",
    "# Extraction échantillon de test\n",
    "inseeTest=insee[testi,]  \n",
    "summary(inseeAppt) # vérifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(inseeTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Régression logistique\n",
    "La régression logistique est une adaptation du modèle linéaire en vue de la prédiction d'une variable (binomiale) à deux modalités correspondant bien à l'objectif recherché. \n",
    "\n",
    "*Attention*, les instructions ci-dessous sont données à titre indicatif; en effet, comme chaque groupe dispose d'un échantillon, dépendant de `xxx`, différent, les sélections et listes de variables doivent être adaptées à la situation rencontrée.\n",
    "\n",
    "\n",
    "La régression logistique est estimée dans R un considérant un cas particulier de modèle linéaire général (fonction `glm`) de densité binomiale et de fonction lien la fonction lien canonique (logistique). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimation du modèle complet sans interaction\n",
    "res.logit=glm(Asvi~.,data=inseeAppt,family=binomial)\n",
    "# tests de nullité des coefficients\n",
    "anova(res.logit,test=\"Chisq\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Commentaires sur les *p*-valeurs.\n",
    "\n",
    "#### Choix de modèle\n",
    "Une sélection de variables s'impose en utilisant une procédure automatique. Compte tenu du nombre raisonnable de variables, plusieurs stratégies peuvent être envisagées par minimisation du critère d'Akaïke (AIC). Noter bien que le critère utilisé par cette fonction de R est plus prédictif qu'explicatif.\n",
    "\n",
    "Voici celle descendante : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.logit=glm(Asvi~.,data=inseeAppt,family=binomial)\n",
    "res.step=step(res.logit,trace=0)\n",
    "# variables du modèles\n",
    "anova(res.step,test=\"Chisq\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Celle pas à pas : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2.logit=glm(Asvi~1,data=inseeAppt,family=binomial)\n",
    "res2.step=step(res2.logit,direction=\"both\",\n",
    "  scope=list(lower=~1, upper=~Sexe+Age+Tage+Couple+\n",
    "  Vmatri+Diplome+Occupa+Work+statut+Herit+Pere+Mere+ \n",
    "  Gparp+gparm+Jgrav+Livep+Epalo+fepsal+vmob+livdf+\n",
    "  pel+cel+qpep+asdecv+Retrait+Qpea+Urbani+Zeat+\n",
    "  Nbenf+Nbenfq+Iogoc+terre+dette+bdetre+hdetvo),trace=0) \n",
    "# observer les p-values\n",
    "anova(res2.step,test=\"Chisq\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparer les deux modèles. \n",
    "\n",
    "On peut par ailleurs se poser la question de la nécessité ou non de prendre en compte des interactions dans la démarche pas à pas ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res3.logit=glm(Asvi~1,data=inseeAppt,family=binomial)\n",
    "res3.step=step(res3.logit,direction=\"both\",\n",
    "  scope=list(lower=~1,upper=~(Sexe+Tage+Work+Herit+\n",
    "  Epalo+fepsal+vmob+livdf+pel+cel+qpep+Retrait+Qpea+\n",
    "  Urbani+Zeat+Nbenfq+Iogoc+bdetre)**2), trace=0) \n",
    "# observer les p-values\n",
    "anova(res2.step,test=\"Chisq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rappel** Chaque groupe dispose d'un échantillon d'apprentissage différent dépendant de l'initialisation du générateur. Les \"meilleurs\" modèles peuvent donc différer d'un groupe à l'autre et par rapport à ce qui est présenté dans ce texte.\n",
    "\n",
    "Les modèles obtenus peuvent différer et certaines variables présenter des *p*-valeurs non significatives. Le modèle proposé par minimisation du critère AIC est peut-être trop complexe. Il s'agit donc de comparer les valeurs prédictives de ces modèles ou de sous modèles par validation croisée en retirant les variables les moins significatives une à une. La bibliothèque `boot` propose une procédure de validation croisée adaptée à la fonction `glm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(boot)\n",
    "# premier modele\n",
    "res.logit=glm(Asvi~Sexe+Tage+ Work+Herit+fepsal+vmob+\n",
    "  livdf+pel+cel+qpep+Retrait+Qpea+Urbani+Zeat+Nbenfq+\n",
    "  Iogoc+bdetre,data=inseeAppt,family=binomial)      \n",
    "cv.glm(inseeAppt,res.logit,K=10)$delta[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deuxieme modele\n",
    "res2.logit=glm(Asvi ~ vmob+Tage+Epalo+Work+livdf+\n",
    "   Herit+qpep+bdetre+Iogoc+Nbenfq+fepsal+Sexe+Qpea+\n",
    "   Zeat+Urbani+Retrait+pel,data=inseeAppt,\n",
    "   family=binomial)      \n",
    "cv.glm(inseeAppt,res2.logit,K=10)$delta[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# troisième modele avec interactions\n",
    "res3.logit=glm(Asvi ~ vmob+Tage+Epalo+Work+livdf+\n",
    "   Herit+qpep+bdetre+Iogoc+fepsal+Nbenfq+Sexe+\n",
    "   Qpea+Zeat+Urbani+Retrait+pel+cel+vmob:Tage+\n",
    "   Tage:Iogoc+Work:Iogoc+Work:Herit+qpep:Qpea+\n",
    "   vmob:Epalo+livdf:Nbenfq+livdf:Urbani+\n",
    "   qpep:Iogoc+vmob:fepsal+bdetre:pel+Nbenfq:pel+\n",
    "   Zeat:pel+Tage:cel+Sexe:Urbani+bdetre:Sexe+\n",
    "   bdetre:fepsal+Nbenfq:Retrait,data=inseeAppt,\n",
    "   family=binomial)      \n",
    "cv.glm(inseeAppt,res3.logit,K=10)$delta[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retenir le meilleur modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prévision de l'échantillon test\n",
    "Les commandes ci-dessous calculent  la prévision de la variable `Asvi pour l'échantillon test et croisent la variable prédite avec la variable observée afin de construire la matrice de confusion et estimer le taux d'erreur avec une probabilité seuil de 0,5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.logit=predict(res3.logit,newdata=inseeTest)>0.5\n",
    "table(pred.logit,inseeTest$Asvi==\"AsO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Q** Commentaires sur cette matrice de confusion.\n",
    "\n",
    "Noter le taux d'erreur et sans doute le grand optimisme de la validation croisée.\n",
    "\n",
    "#### Construction de la courbe ROC\n",
    "Le tracer de cette courbe fait varier le seuil de la probabilité pour évaluer comment se comporte les caractéristiques de sensibilité et spécificité du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ROCR)\n",
    "roclogit=predict(res2.logit, newdata=inseeTest,type=\"response\")\n",
    "predlogistic=prediction(roclogit,inseeTest$Asvi)\n",
    "perflogistic=performance(predlogistic, \"tpr\",\"fpr\")\n",
    "options(repr.plot.width=4, repr.plot.height=4)\n",
    "plot(perflogistic,col=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Que penser de la qualité de ce modèle?\n",
    "### Arbres de décision binaires\n",
    "Cette section a pour objectif la construction d'un arbre de discrimination (classification tree) et son élagage par validation croisée pour optimiser sa capacité de discrimination.\n",
    "\n",
    "#### Estimation\n",
    "Deux librairies `tree` et `rpart` et bien d'autres, proposent les techniques CART avec des algorithmes analogues à ceux développés dans Splus mais moins de fonctionnalités; `rpart` fournissant des graphes plus explicites et une procédure d'élagage plus performante est préférée.\n",
    "\n",
    "La première estimation favorise un arbre très détaillé c'est-à-dire avec un très faible coefficient de pénalisation de la complexité de l'arbre et donc du nombre de feuilles. Le critère d'hétérogénéité est l'entropie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(rpart) # Chargement de la librairie\n",
    "res.tree=rpart(Asvi~.,data=inseeAppt, parms=list(split='information'),cp=0.001)\n",
    "# summary(res.tree) # Quelques renseignements (trop)\n",
    "options(repr.plot.width=8, repr.plot.height=8)\n",
    "plot(res.tree) # Tracé de l'arbre\n",
    "text(res.tree) # Ajout des légendes des noeuds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est évident que l'arbre présente trop de feuilles. Une première façon de l'élaguer consiste à tracer la décroissance de l'erreur relative en fonction du coefficient de complexité c'est-à-dire aussi en fonction de la taille de l'arbre ou nombre de feuilles. La procédure est mal explicitée dans la documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=8, repr.plot.height=4)\n",
    "plotcp(res.tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut alors choisir une valeur du coefficient de pénalisation de la complexité pour élaguer l'arbre. Attention, ce choix dépend de l'échantillon tiré. Il peut être différent de celui ci-dessous. La valeur de cp choisie correspond à la première valeur d''erreur relative'' sous les pointillés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(partykit)\n",
    "res2.tree=prune(res.tree,cp=0.0069) \n",
    "options(repr.plot.width=4, repr.plot.height=4)\n",
    "plot(as.party(res2.tree),gp = gpar(fontsize = 11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Élagage par validation croisée \"explicite\"\n",
    "\n",
    "La commande suivante calcule les prédictions obtenues pas 10-fold validation croisée pour chaque arbre élagué suivant les valeurs du coefficients de complexité. La séquence de ces valeurs doit être adaptée à l'exemple traité. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.tree=rpart(Asvi~.,data=inseeAppt,parms=list(split='information'),\n",
    "               control = rpart.control(cp = .001))\n",
    "xmat = xpred.rpart(res.tree,xval=10)\n",
    "# Comparaison de la valeur prédite \n",
    "# avec la valeur observée.\n",
    "xerr=as.integer(inseeAppt$Asvi)!= xmat \n",
    "# Calcul et affichage des estimations \n",
    "# des taux d'erreur\n",
    "apply(xerr, 2, sum)/nrow(xerr) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Comparer les choix de pénalisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elagage puis affichage de l'arbre\n",
    "res3.tree=prune(res.tree,cp=0.001816418) \n",
    "options(repr.plot.width=8, repr.plot.height=8)\n",
    "plot(as.party(res3.tree),gp = gpar(fontsize = 11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Interpréter, ou non, les arbres. Que dire du choix des variables comparativement aux autres méthodes ? \n",
    "\n",
    "#### Prévision de l'échantillon test\n",
    "Les commandes ci-dessous calculent  la prévision de la variable `Asvi` pour l'échantillon test et croisent la variable prédite avec la variable observée afin de construire les matrices de confusion et donc d'estimer les taux d'erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.tree=predict(res3.tree, newdata=inseeTest,type=\"class\")\n",
    "table(pred.tree,inseeTest$Asvi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Noter et comparer les taux d'erreur ainsi que les courbes ROC :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROCrpart=predict(res3.tree,newdata=inseeTest,type=\"prob\")[,2]\n",
    "predrpart=prediction(ROCrpart,inseeTest$Asvi)\n",
    "perfrpart=performance(predrpart,\"tpr\",\"fpr\")\n",
    "# tracer les courbes ROC\n",
    "options(repr.plot.width=4, repr.plot.height=4)\n",
    "plot(perflogistic,col=1) \n",
    "# en les superposant pour mieux comparer\n",
    "plot(perfrpart,col=2,add=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Quelle meilleure méthode entre la régression logistique et un arbre de décision?\n",
    "\n",
    "## Approche \"industrielle\"\n",
    "### Tests de différents modèles\n",
    "L'étude se limite à une utilisation de la librairie `caret` (Kunh, 2008) pour quelques unes des méthodes de modélisation proposées. C'est un \"méta-package\" qui englobe dans une seule fonction  `train` l'appel des différentes fonctions d'estimation d'autre packages. La commande `library` est incluse mais évidemment les packages utilisés doivent avoir été chargés.\n",
    "\n",
    "### Calcul parallèle\n",
    "Par ailleurs, même sous windows, `caret` offre simplement des possibilités de parallèlisation en utilisant la package `doParallel`. Même si les algorithmes des différentes méthodes d'apprentissage ne sont pas parallélisés, les itérations des calculs de validations croiser pour l'optimisation des paramètres sont effectivement parallélisés avec un gain de temps très appréciable fonciton du nombre de processeurs. Ceci est obtenu en exécutant les commandes suivantes en supposant que 4 processeurs sont disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(doParallel)\n",
    "cl <- makeCluster(4)\n",
    "registerDoParallel(cl) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation des données\n",
    "Extraction des échantillons d'apprentissage et de test. Attention, le mode d'utilisation ou d'appel de la principale fonction : `train` de `caret` dépend du type des variables explicatives et de la méthode utilisée; c'est une limitation de l'aspect \"généralisation\" de ce méta-package. Pas de problème lorsque les variables $X^j$ sont toutes quantitatives mais des traitements différents des variables $X^j$  qualitatives. Les facteurs sont, ou non, transformés en *dummy* variables c'est-à-dire en indicatrices: une par modalité pour certaines méthodes. Ce n'est pas une procédure \"optimale\" en sélection de variables au moment de l'interprétation!\n",
    "\n",
    "Dans le premier cas, tout quantitatif, il faut séparer les variables *X* de la variable cible à expliquer *Y*. Dans le 2ème, variables qualitatives, et pour certaines méthodes,  il faut utiliser la syntaxe classique en R de définition d'un modèle (*formulae*) pour éviter un message d'erreur.\n",
    "\n",
    "La constitution de l'échantillon test est similaire au traitement précédent avec une proportion identique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(caret)\n",
    "# indices de l'échantillon d'apprentissage \n",
    "set.seed(xxx)\n",
    "inTrain = createDataPartition(insee[,1], p = .7476, list = FALSE)\n",
    "# Extraction des échantillons\n",
    "# data frames apprentissage et test\n",
    "inseeAppt=insee[inTrain,]\n",
    "inseeTest=insee[-inTrain,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est recommandé de centrer et réduire les variables quantitatives dans plusieurs méthodes. C'est fait systématiquement sauf dans le cas présent où les variables sont essentiellement qualitatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# estimation des erreurs par validation croisée\n",
    "cvControl=trainControl(method=\"cv\",number=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation et optimisation des modèles\n",
    "La librairie intègre beaucoup plus de méthodes que celles utilisées. Consulter la liste des méthodes disponibles dans l'aide de la fonction: `?train` pour en tester d'autres.  Exécuter successivement les blocs de commandes pour tracer séparamment chacun des graphes afin de contrôler le bon comportement de l'optimisation du paramètre ou des paramètres de complexité de chaque modèle.\n",
    "\n",
    "L'utilisation de certaines méthodes, comme la régression logistique, est sans doute moins flexible qu'en utilisation \"manuelle\" en particulier dans le choix de l'algorithme de sélection de variables. Il faut se montrer (très) patient pour certaines optimisations alors que d'autres sont immédiates, voire inutiles. Le paramètre `tuneLength` caractérise un `effort` d'optimisation, c'est en gros le nombre de valeurs de paramètres testées sur une grille fixée automatiquement. En prenant plus de soin et aussi plus de temps, il est possible de fixer précisément des grilles pour les valeurs du ou des paramètres optimisés pour chaque méthode.\n",
    "\n",
    "**Q** Pour chacune des méthodes ou algorithmes utilisés ci-dessous, préciser quels sont les paramètres à optimiser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Régression logistique par sélection backward\n",
    "C'est assez fastidieux, à comparer avec la sélection Lasso de Scikit-learn en python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glmFit = train(Asvi~.,data=inseeAppt,method = \"glmStepAIC\",trControl = cvControl)\n",
    "glmFit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Réseaux de neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(2)\n",
    "nnetFit = train(Asvi~.,data=inseeAppt,\n",
    "    method = \"nnet\", tuneLength = 6,\n",
    "    trControl = cvControl)\n",
    "nnetFit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(nnetFit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Quelles sont les values optimales de quels paramètres des réseaux de neurones?\n",
    "\n",
    "#### Arbre de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(2)\n",
    "rpartFit = train(Asvi~.,data=inseeAppt,\n",
    "   method = \"rpart\", tuneLength = 10,\n",
    "   trControl = cvControl)\n",
    "rpartFit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(rpartFit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Random forest* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(2)\n",
    "rfFit = train(Asvi~.,data=inseeAppt,\n",
    "   method = \"rf\", tuneLength = 4,\n",
    "   trControl = cvControl)\n",
    "rfFit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(rfFit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Gradient Boosting Machine*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(2)\n",
    "gbmFit = train(Asvi~.,data=inseeAppt,\n",
    "   method = \"gbm\", tuneLength = 4,\n",
    "   trControl = cvControl)\n",
    "gbmFit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(gbmFit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Remarque* : plusieurs méthodes comme $k$-nn, les SVM, l'analyse discriminante ne sont pas exécutables directement du fait du caractère qualitatif des variables explicatives. Il faudrait les remplacer par des variables indicatrices des modalités ou les coordonnées des individus d'une AFC du tableau disjonctif complet, c'est-à-dire les composantes principales de l'ACP des profils lignes associée à cette AFC; coordonnées obtenues par une SVD du tableau disjonctif complet en considérant les métriques du chi2. Consulter la [vignette sur l'AFCM](http://wikistat.fr/pdf/st-m-explo-afcm.pdf) pour plus de précisions. Ce serait encore d'autres stratégies à tester...\n",
    "\n",
    "Cette stratégie (utilisation des coordonnées de l'AFCM) est mise en oeuvre pour la [prévision d'une pathologie coronarienne](https://github.com/wikistat/Apprentissage/blob/master/Diag-coro/Apprent-R-DiagCoro.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Extrem Gradient Boosting*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(2)\n",
    "xgboostFit = train(Asvi~.,data=inseeAppt,\n",
    "   method = \"xgbTree\", tuneLength = 4,\n",
    "   trControl = cvControl)\n",
    "plot(xgboostFit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prévisions et erreurs en test\n",
    "Les méthodes sélectionnées et optimisées sont ensuite appliquées à la prévision de l'échantillon test. Estimation du taux de bien classés :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=list(rlog=glmFit,nnet=nnetFit,rtree=rpartFit,rf=rfFit,gbm=gbmFit,XGB=xgboostFit)  \n",
    "testPred=predict(models, newdata = inseeTest)\n",
    "# taux de bien classés\n",
    "lapply(testPred,function(x)mean(x==inseeTest[,\"Asvi\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tracer les courbes ROC pour analyser spécificité et sensibilité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courbes ROC\n",
    "library(ROCR)\n",
    "testProb=predict(models, newdata = inseeTest, type=\"prob\")\n",
    "predroc=lapply(testProb, function(x)prediction(x[,1], inseeTest[,\"Asvi\"]==\"AsN\"))\n",
    "perfroc=lapply(predroc, function(x)performance(x, \"tpr\", \"fpr\"))\n",
    "# Tracer les courbes ROC\n",
    "    options(repr.plot.width=8, repr.plot.height=8)\n",
    "plot(perfroc$rlog,col=1)\n",
    "plot(perfroc$nnet,col=2,add=TRUE)\n",
    "plot(perfroc$rtree,col=3,add=TRUE)\n",
    "plot(perfroc$rf,col=4,add=TRUE)\n",
    "plot(perfroc$gbm,col=5,add=TRUE)\n",
    "plot(perfroc$XGB,col=6,add=TRUE)    \n",
    "legend(\"bottomright\",legend=c(\"rlog\",\"nnet\", \"Tree\",\"RF\",\"gbm\",\"XGB\"),col=c(1:6),pch=\"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Comparer, commenter. Une méthodes est-elle à retenir ? A éviter ?\n",
    "\n",
    "#### Importance des variables\n",
    "Certaines méthodes sont très peu explicites car de véritables \"boîtes noires\", quant au rôle et impact des variables sur la prévision des observations. Néanmoins, des indicateurs d'importance sont proposés pour les forêts aléatoires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfFit2=randomForest(inseeAppt[,-1], inseeAppt[,\"Asvi\"],importance=T)\n",
    "imp.mdrr=sort(rfFit2$importance[,3], decreasing=T)[1:20]\n",
    "par(xaxt=\"n\")\n",
    "plot(imp.mdrr,type=\"h\",ylab=\"Importance\", xlab=\"Variables\")\n",
    "points(imp.mdrr,pch=20)\n",
    "par(xaxt=\"s\")\n",
    "axis(1,at=1:20,labels=names(imp.mdrr), cex.axis=0.8,las=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Commenter ces importance notamment par rapport aux choix de variables en régression et dans l'arbre de décision.\n",
    "### Automatisation\n",
    "L'échantillon n'est pas de faible taille, mais les estimations des taux de bien classés comme le tracé des courbes ROC sont très dépendants de l'échantillon test ; on peut s'interroger sur l'identité du modèle le plus performant comme sur la réalité des différences entre les méthodes. Il est alors important d'itérer le processus sur plusieurs échantillons tests aléatoires: validation croisée *Monte Carlo*.\n",
    "\n",
    "Exécuter, c'est un peu long ... la fonction en annexe en choisissant les méthodes semblant les plus performantes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.insee=pred.autom(Asvi~.,data=insee,p = .7476,\n",
    "   methodes=c(\"glmStepAIC\",\"nnet\",\"rf\",\"gbm\",\"xgbTree\"),N=10,\n",
    "   size=c(4,4,4,4,4),type=\"prob\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis calculer :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taux de bien classés\n",
    "obs=pred.insee$obs\n",
    "prev.insee=pred.insee$pred\n",
    "res.insee=lapply(prev.insee,function(x)apply((x>0.5)==(obs==1),2,mean))\n",
    "# Moyennes des taux de bien classés par méthode\n",
    "lapply(res.insee,mean)\n",
    "# Distributions des taux de bien classés\n",
    "boxplot(data.frame(res.insee))\n",
    "# Tracer les courbes ROC moyennes\n",
    "predroc.insee=lapply(prev.insee, function(x)prediction(x,obs==1))\n",
    "perfroc.insee=lapply(predroc.insee, function(x)performance(x,\"tpr\",\"fpr\"))\n",
    "plot(perfroc.insee$glmStepAIC,col=1,lwd=1.5, avg=\"vertical\")\n",
    "plot(perfroc.insee$nnet,col=2,add=TRUE, lwd=1.5,avg=\"vertical\")\n",
    "plot(perfroc.insee$rf,col=3,add=TRUE, lwd=1.5,avg=\"vertical\")\n",
    "plot(perfroc.insee$gbm,add=TRUE,col=4,lwd=1.5, avg=\"vertical\")\n",
    "plot(perfroc.insee$xgbTree,add=TRUE,col=5,lwd=1.5, avg=\"vertical\")\n",
    "legend(\"bottomright\",legend=c(\"rlogit\",\"nnet\", \"RF\", \"boost\", \"XGB\"),col=c(1:5),pch=\"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Commenter les résultats, peut-on conseiller une méthode ? Que dire du nombre très important de méthodes proposées au regard de ces résultats ?\n",
    "\n",
    "**Q** Les fonctions de `Scikit-learn` en python feront-t-elles mieux pour la qualité de prévision et le temps de calcul? \n",
    "\n",
    "**Attention**\n",
    "- Ne pas  généraliser sur la base de ces seuls résultats, \n",
    "- l'apparente interprétabilité de la régression logistique est assez illusoire compte tenu du nombre de variables indicatrices introduites dans le modèle.\n",
    "- Les méthode généralement utilisées sont une adaptation d'un *classifieur bayésien* qui peut facilement être mis à jour à chaque identification d'un pourriel par l'utilisateur. \n",
    "\n",
    "\n",
    "## Annexe: programme de validation croisée *Monte Carlo*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred.autom=function(formul,data,p=1/2,\n",
    "   methodes=c(\"knn\",\"rf\"),size=c(10,2),\n",
    "   xinit=11,N=10,typerr=\"cv\",number=4,type=\"raw\")\n",
    "# Fonction de prévision de N échantillons tests\n",
    "# par une liste de méthodes de régression \n",
    "# ou classification (uniquement 2 classes)\n",
    "# Optimisation des paramètres par validation \n",
    "# croisée (défaut) ou bootstrap ou... (cf. caret)\n",
    "# data : data frame avec la variable cible Y\n",
    "# en première colonne\n",
    "# Formule sous la forme Y~.  \n",
    "# p : proportion entre apprentissage et test\n",
    "# methodes : liste des méthodes de discrimination\n",
    "# size : e grille des paramètres à optimiser\n",
    "# xinit : générateur de nombres aléatoires\n",
    "# N : nombre de réplications apprentissage / test\n",
    "# typerr : \"cv\" ou \"boo\" ou \"oob\"\n",
    "# number : nombre de répétitions CV ou bootstrap\n",
    "# pred : liste des matrices de prévision\n",
    "{# type d'erreur\n",
    "Control=trainControl(method=typerr,number=number)\n",
    "# initialisation du générateur \n",
    "set.seed(xinit)\n",
    "# liste de matrices stockant les prévisions\n",
    "# une par méthode\n",
    "inTrain=createDataPartition(data[,1],p=p,list=FALSE)\n",
    "ntest=length(data[-inTrain,1])\n",
    "pred=vector(\"list\",length(methodes))\n",
    "names(pred)=methodes\n",
    "pred=lapply(pred,function(x)x=matrix(0,\n",
    "   nrow=ntest,ncol=N))\n",
    "obs=matrix(0,ntest,N)\n",
    "set.seed(xinit)\n",
    "for(i in 1:N)  # N itérations\n",
    "{# indices de l'échantillon d'apprentissage\n",
    " inTrain=createDataPartition(data[,1],p=p,list=FALSE)\n",
    "# Extraction des échantillons\n",
    "Appt=data[inTrain,]\n",
    "Test=data[-inTrain,]\n",
    "# stockage des observés de testY\n",
    "obs[,i]=Test[,1]\n",
    "# estimation et optimisation des modèles \n",
    "# pour chaque méthode de la liste\n",
    "for(j in 1:length(methodes))\n",
    "{# modélisation \n",
    "modFit = train(formul,data=Appt,\n",
    "   method = methodes[j], tuneLength = size[j],\n",
    "   trControl = Control)\n",
    "# prévisions\n",
    "if (type==\"prob\")  pred[[j]][,i]=predict(modFit,\n",
    "    newdata = Test,type=type)[,1]\n",
    "else pred[[j]][,i]=predict(modFit,newdata=Test)\n",
    "}}\n",
    "list(pred=pred,obs=obs)} # résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
