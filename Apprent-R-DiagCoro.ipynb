{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "\n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" style=\"float:right; max-width: 250px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Scénarios d'Apprentissage Statistique](https://github.com/wikistat/Exploration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modélisation de données cliniques en <a href=\"https://cran.r-project.org/\"><img src=\"https://cran.r-project.org/Rlogo.svg\" style=\"max-width: 40px; display: inline\" alt=\"R\"/></a>:  Diagnostic coronarien "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Résumé\n",
    "Modélisation de la variable binaire de présence d'une pathologie coronarienne. Comparaison de la plupart des méthodes et algorithmes; intérêt, ou non, d'ajouter des variables ou caractéristiques (*features*) obtenues par analyse de correspondances de toutes les variables rendues qualitatives. Utilisation de [`caret`](http://topepo.github.io/caret/index.html) pour l'optimisation des valeurs des paramètres et introducton à l'implémentation de [`xgboost`](https://xgboost.readthedocs.io/en/latest/) en R.\n",
    "## Introduction\n",
    "Des données publiques disponibles sur le site [UCI repository](http://archive.ics.uci.edu/ml/) décrivent des facteurs de risque et résultats cliniques: 13 parmi 75 de l’étude originale de [Detrano et al. (1989)](http://www.ajconline.org/article/0002-9149%2889%2990524-9/abstract), liés à une maladie coronarienne (athérosclérose). Celle-ci est jugée présente lorsque tous les vaisseaux coronariens sont obstrués à plus de 50% par des athéromes. Les variables étudiées sont observées sur un échantillon de 270 patients admis dans une clinique de Cleveland (Ohio) à la suite de douleurs thoraciques pouvant être dues à une angine de poitrine. Elles sont décrites dans le tableau ci-dessous:\n",
    "\n",
    "Num| Code | Libellé | Valeurs\n",
    "-|--|--|--\n",
    "1|`Age`   |  \t\t\n",
    "2|`Sexe`|   |sxF, sxM\n",
    "3|`Douleur`|\tThoracique|\tdlA (angine typique), dlb(atypique) dlc(différent) dlD(asymptom.)\n",
    "4|`Tension`|\tSystolique|\tmmHg à l’admission et au repos\n",
    "5|`Cholest`|\tTaux|\tmg/dl (préférable<200, limite entre 200 et 240, risqué au-delà)\n",
    "6|`Sucre`|\tTaux à jeun|\tscN (<120mg/dl), scO (>120mg/dl)\n",
    "7|`Cardio`|\tECG au repos|\tcdA (Normal) cdB (ST/T anormal) cdC (hypertrophie ventr. gauche)\n",
    "8|`FreqM`|\tFréquence|\tcardiaque maximum lors du test d’effort\n",
    "9|`AngInd`|\tAngine induite|\tpar l’effort :  tmA (oui), tmB (non)\n",
    "10|`PicInd`|\tDépression ST|\tInduite par effort / repos\n",
    "11|`PentInd`|\tSegment ST| \tInduit à l’effort piA(ascendante), piB(plate), piC(descendante)  \n",
    "12|`Nvais`|\tNombre de|\tvaisseaux fl0, fl1, fl2, fl3 majeurs colorés par fluoroscopie\n",
    "13|`Thal`|\tScintigraphie|\tthN(normal) thF(défaut fixé) thR(défaut révers.) avec effort\n",
    "14|`Coro`|\tCoronaropathie|\tCoA(Absence), CoP(Présence)\n",
    "\n",
    "Certaines sont associées à des risques potentiels et d’autres sont résultats d’examens cliniques au repos ou à la suite d’un test d’effort. Les variables 1, 4, 5, 8, 10 sont quantitatives, les autres sont qualitatives dont certaines binaires : 2, 6, 9, 14. Le diagnostic (variable `Coro`) a été établi par une *angiographie* permettant de mesurer l’obstruction des artères coronariennes. \n",
    "\n",
    "Après la [phase exploratoire](https://github.com/wikistat/Exploration/blob/master/Diag-coro/Explo-R-DiagCoro.ipynb) l’objectif sur ces données est de construire un modèle de prévision de la variable `Coro` à partir de l’observation des autres, pas ou peu invasives, car l’angiographie est un examen invasif comportant des risques. C'est en fait plus qu'un examen puisqu'il permet simultanément de poser par exemple des *stents* pour faciliter le débit sanguin. \n",
    "\n",
    "**Répondre aux questions en s'aidant des résultats des exécutions**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Préparation des données\n",
    "### 1.1  Variables disponibles\n",
    "Cette étape résume rapidement la suite des commandes qui découlent de la phase [phase exploratoire](https://github.com/wikistat/Exploration/blob/master/Diag-coro/Explo-R-DiagCoro.ipynb) des données qu'il est vivement conseillé d'avoir pratiquée pour se familiariser avec celles-ci.\n",
    "\n",
    "Lecture des données et préparation pour construire le *dataFrame*. Les données sont lues et les codes des modalités (niveaux des facteurs) sont renommés de façon explicite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/data/\"\n",
    "#path=\"\"\n",
    "heart=read.table(paste(path,\"heart.dat\",sep=\"\"))\n",
    "# recodage des classes et nom des variables\n",
    "heart=data.frame(\n",
    "    Age=heart[,1],\n",
    "    Sexe=factor(as.factor(heart[,2]),labels=c(\"sxF\",\"sxM\")),\n",
    "    Douleur=factor(as.factor(heart[,3]),labels=c(\"dlA\",\"dlB\",\"dlC\",\"dlD\")),\n",
    "    Tension=heart[,4],\n",
    "    Cholest=heart[,5],\n",
    "    Sucre=factor(as.factor(heart[,6]),labels=c(\"scN\",\"scO\")),\n",
    "    Cardio=factor(as.factor(heart[,7]),labels=c(\"cdA\",\"cdB\",\"cdC\")),\n",
    "    FreqM=heart[,8],\n",
    "    AngInd=factor(as.factor(heart[,9]),labels=c(\"tmA\",\"tmB\")),\n",
    "    PicInd=heart[,10],\n",
    "    PenteInd=factor(as.factor(heart[,11]),labels=c(\"piA\",\"piB\",\"piC\")),\n",
    "    Nvais=factor(as.factor(heart[,12]),labels=c(\"fl0\",\"fl1\",\"fl2\",\"fl3\")),\n",
    "    Thal=factor(as.factor(heart[,13]),labels=c(\"thN\",\"thF\",\"thR\")),\n",
    "    Coro=factor(as.factor(heart[,14]),labels=c(\"CoA\",\"CoP\")))\n",
    "summary(heart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Découpage des variables quantitatives en trois classes pour permettre une analyse factorielle multiple des correspondances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AgeQ=cut(heart$Age,breaks=quantile(heart$Age,c(0,.33,.66,1)),labels=c(\"AgeA\",\"AgeB\",\"AgeC\"),include.lowest = TRUE)\n",
    "TensQ=cut(heart$Tension,breaks=quantile(heart$Tension,c(0,.33,.66,1)),labels=c(\"TensA\",\"TensB\",\"TensC\"),include.lowest = TRUE)\n",
    "CholQ=cut(heart$Cholest,breaks=quantile(heart$Cholest,c(0,.33,.66,1)),labels=c(\"CholA\",\"CholB\",\"CholC\"),include.lowest = TRUE)\n",
    "FreQ=cut(heart$FreqM,breaks=quantile(heart$FreqM,c(0,.33,.66,1)),labels=c(\"FreqA\",\"FreqB\",\"FreqC\"),include.lowest = TRUE)\n",
    "PicQ=cut(heart$PicInd,breaks=quantile(heart$PicInd,c(0,.33,.66,1)),labels=c(\"PicA\",\"PicB\",\"PIcC\"),include.lowest = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppression d'une modalité trop rare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart[heart$Cardio==\"cdB\",\"Cardio\"]=\"cdA\"\n",
    "heart$Cardio=factor(heart$Cardio,exclude=NULL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création finale du *dataFrame*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heartT=data.frame(heart,AgeQ,TensQ,CholQ,FreQ,PicQ)\n",
    "summary(heartT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Gestion, analyse des variables rendues qualitatives\n",
    "L'étude exploratoire montre l'importance des variables qualitatives. en particulier, l'âge n'intervient pas comme risque de la même façon en fonction du genre des patients. Aussi, une nouvelle variable croisant sexe et âge est construite et une version simplifiée, avec 3 modalités au lieu de 6, est ajoutée à la base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélection des seules variables qualitatives\n",
    "heartQ=heartT[,-c(1,4,5,8,10)]\n",
    "summary(heartQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nouvelle variable pour intégrer l'interaction Sexe x Age\n",
    "SexAge=heartQ$Sexe:heartQ$AgeQ\n",
    "heartQ=data.frame(heartQ,\"SexAge\"=SexAge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplifier la variable en regroupant les jeunes hommes et femmes dans la même classe\n",
    "SxAg=as.factor(rep(c(\"sHFageA\",\"sFageBC\",\"sHageBC\"),90))\n",
    "SxAg[heartQ$AgeQ==\"AgeA\"]=\"sHFageA\"\n",
    "SxAg[heartQ$SexAge==\"sxF:AgeB\" | heartQ$SexAge==\"sxF:AgeC\"]=\"sFageBC\"\n",
    "SxAg[heartQ$SexAge==\"sxM:AgeB\" | heartQ$SexAge==\"sxM:AgeC\"]=\"sHageBC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complétion du data frame\n",
    "heartQ2=data.frame(heartQ[,-15],SxAg)\n",
    "summary(heartQ2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Ajout de caractéristiques (*features*)\n",
    "Cette étude teste la stratégie suivante: ajouter des nouvelles variables ou *features* sous la forme des composantes principales issues de l'AFCM du tableau disjoinctif complet. Si toutes les variables étaient quantitatives, cela reviendrait à ajouter les composantes principales d'une analyse en composantes principales mais en prenant toutes celles qualitatives plus les quantitatives découpées en classes, c'est une AFCM qui convient.\n",
    "\n",
    "Cette approche a un autre avantage, elle permet de considérer des méthodes de classification supervisée qui n'autorisent que des variables quantitatives comme variables prédictives tout en conservant l'information apportée par les variables qualitatives. \n",
    "\n",
    "**Q** Quelles sont les principales méthodes de classifications supervisée concernées?\n",
    "\n",
    "**Q** Quelle autre approche est mise en oeuvre pour contourner ce problème?\n",
    "\n",
    "**R** :L'autre approche, souvent utilisée, consiste à remplacer toutes les variables qualitatives par les paquets de leurs indicatrices (*dummy variables*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construction des [composantes principales d'une AFCM](http://wikistat.fr/pdf/st-m-explo-afcm.pdf)\n",
    "Les nouvelles variables (composantes principales) sont construites à l'aide d'une [AFCM](http://wikistat.fr/pdf/st-m-explo-afcm.pdf) disponible dans la librairie *FactoMineR*. Elles sont encore les composantes principales de l'ACP, avec la métrique dite du Chi2, du tableau disjonctif complet.\n",
    "\n",
    "Une première exécution fournit la représentation graphique de toutes les modalités dans le premier plan factoriel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(FactoMineR)\n",
    "afc=MCA(heartQ2,quali.sup=c(1,9,10),graph=F)\n",
    "options(repr.plot.width=5, repr.plot.height=5)\n",
    "par(mar=c(2.1, 2.1, .1, .1))\n",
    "plot.MCA(afc,invisible=c(\"ind\"),cex=0.8,habillage=\"quali\",palette=palette(rainbow(14)),title=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'interprétation de ce graphique était un des objectifs de la [phase exploratoire](https://github.com/wikistat/Exploration/blob/master/Diag-coro/Explo-R-DiagCoro.ipynb). Remarquer simplement la position des modalités liées à la présence ou non de la pathologie: `CoP, CoA`, et celles représentant les facteurs de risque, dont `sHageBC` (hommes plus âgés), alors que le cholestérol (`CholA, B, C`) augmente avec l'âge (tous genres confondus) sans être nécessairement lié avec l'aggravation du risque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regrouper toiutes les variables dans un même dataFrame\n",
    "heartT=data.frame(heart,heartQ2[,c(10:15)])\n",
    "summary(heartT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Séparation des échantillons apprentissage et test\n",
    "**Q** Qu'est ce qui nécessite cette démarche?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# séparation apprentissage / test\n",
    "set.seed(11)\n",
    "npop=nrow(heartT)\n",
    "\n",
    "ntest=100\n",
    "testi=sample(1:npop,ntest)\n",
    "appri=setdiff(1:npop,testi)\n",
    "\n",
    "datapp=heartT[appri,]\n",
    "datest=heartT[testi,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les étapes suivantes calculent les composantes principales de l'AFCM ou coordonnées des individus dans la base des \n",
    "vecteurs propres. \n",
    "\n",
    "**Q** Les individus, patients, de l'étude appartenant à l'échantillon teste sont considérés comme *individus supplémentaires*. Pourquoi?\n",
    "\n",
    "**R**: Il faut calculer également les nouvelles coordonnées des individus du test dans cette base mais ils ne doivent pas participer au calcul des vecteurs et valeurs propres et donc à la définition des axes factoriels. Pour ce faire, ils sont déclarés comme individus en supplémentaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(FactoMineR)\n",
    "summary(heartQ)  \n",
    "afc=MCA(heartQ2[,-9],ind.sup=testi,ncp=9,graph=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(afc$ind$coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(afc$ind.sup$coord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construction des des bases de données échantillon et test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ajout des nouvelles variables\n",
    "datapp=data.frame(datapp,afc$ind$coord)\n",
    "datest=data.frame(datest,afc$ind.sup$coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(datapp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Panoplie des méthodes de classification supervisée\n",
    "Le problème à résoudre est la prévision de la présence d'une coronopathie. C'est donc un problème de discriminaiton binaire que beaucoup de méthodes peuvent aborder.\n",
    "\n",
    "L'objectif est de détrerminer si les composantes principales ont un intérêt ou non pour l'atteinte de l'objectif.\n",
    "\n",
    "### 2.1 [Régression logistique](http://wikistat.fr/pdf/st-m-app-rlogit.pdf)\n",
    "La sélection de variables et donc la complexité du modèle sont optimisées par minimisation du critère AIC avant de calculer l'erreur de prévision sur l'échantillon test.\n",
    "\n",
    "**Q** Quels sont principaux les algorithmes de sélection de variable utilisables pour cet objectif? \n",
    "#### Sur les seules variables initiales quantitatives et qualitatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.log=glm(Coro~1,data=datapp,family=\"binomial\")\n",
    "res.log.step=step(res.log,scope=list(lower=~1,upper=~(Age+Sexe+Douleur+Tension+Cholest+\n",
    "                  AngInd+PicInd+PenteInd+Nvais+Thal+Sucre+Cardio+FreqM+SxAg),\n",
    "                  direction=\"both\"),trace=0)\n",
    "anova(res.log.step, test=\"Chisq\")\n",
    "table(predict(res.log.step,datest,type=\"response\")>0.5,datest[,14]==\"CoP\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sur l'ensemble des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.log=glm(Coro~1,data=datapp,family=\"binomial\")\n",
    "res.log.step=step(res.log,scope=list(lower=~1,upper=~(Age+Sexe+Douleur+Tension+Cholest+\n",
    "                AngInd+PicInd+PenteInd+Nvais+Thal+Sucre+Cardio+FreqM+SxAg+Dim.1+Dim.2+Dim.3+\n",
    "                                    Dim.4+Dim.5+Dim.6+Dim.8+Dim.9)),direction=\"both\",trace=0)\n",
    "anova(res.log.step, test=\"Chisq\")\n",
    "table(predict(res.log.step,datest,type=\"response\")>0.5,datest[,14]==\"CoP\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sur les seules composantes de l'AFCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2.log=glm(Coro~1,data=datapp,family=\"binomial\")\n",
    "res2.log.step=step(res2.log,scope=list(lower=~1,upper=~(Dim.1+Dim.2+Dim.3+Dim.4+\n",
    "                            Dim.5+Dim.6+Dim.8+Dim.9)),direction=\"both\",trace=0)\n",
    "anova(res2.log.step, test=\"Chisq\")\n",
    "table(predict(res2.log.step,datest,type=\"response\")>0.5,datest[,14]==\"CoP\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Que pensez de la capacité des composantes pricipales de l'AFCM à résumer l'information pertinente apportée par les variables? Justifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 [Arbre de décision binaire](http://wikistat.fr/pdf/st-m-app-cart.pdf)\n",
    "Comme précédemment la méthode est comparée sur les deux ensembles de variables.\n",
    "#### Sur les données initiales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(rpart)\n",
    "library(partykit)\n",
    "res.tree=rpart(Coro~.,data=datapp[,1:20],cp=0)\n",
    "par(mar=c(2.1, 2.1, .1, .1))\n",
    "plot(as.party(res.tree),gp = gpar(fontsize = 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(predict(res.tree,datest,type=\"class\"),datest[,14])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Que dire des facteurs de risque identifiés par ce modèle? de la qualité de la prévision? Que signifie `Cp`? Que dire du choix de la valeur?\n",
    "\n",
    "\n",
    "#### Sur toutes les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.tree=rpart(Coro~.,data=datapp,cp=0)\n",
    "options(repr.plot.width=6, repr.plot.height=5)\n",
    "par(mar=c(2.1, 2.1, .1, .1))\n",
    "library(partykit) # si java est bien installé\n",
    "plot(as.party(res.tree),gp = gpar(fontsize = 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(predict(res.tree,datest,type=\"class\"),datest[,14]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sur les composantes de l'AFCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2.tree=rpart(Coro~.,data=datapp[,c(14,21:29)],cp=0)\n",
    "table(predict(res2.tree,datest,type=\"class\"),datest[,14]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 [Réseaux de neurones](http://wikistat.fr/pdf/st-m-app-rn.pdf)\n",
    "Même démarche avec cet algorithme.\n",
    "#### Variables initiales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### nnet\n",
    "library(MASS)\n",
    "library(nnet)\n",
    "res.net=nnet(Coro~.,data=datapp[,1:20],size=5,decay=1,maxit=500)\n",
    "table(predict(res.net,datest,type=\"class\"),datest[,14]) #21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2.net=nnet(Coro~.,data=datapp,size=5,decay=1,maxit=500)\n",
    "table(predict(res.net,datest,type=\"class\"),datest[,14])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Composantes principales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2.net=nnet(Coro~.,data=datapp[,c(14,21:29)],size=5,decay=1,maxit=500)\n",
    "table(predict(res.net,datest,type=\"class\"),datest[,14]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Quelle stratégie vous semble raisonnable? Quel est le rôle du paramètre `decay`? Que manque-t-il à cette étape?\n",
    "### 2.4 [Séparateur à vaste marge](http://wikistat.fr/pdf/st-m-app-svm.pdf)\n",
    "#### Variables initiales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(e1071)\n",
    "res.svm=svm(Coro~.,data=datapp[,1:20],cost=0.5,kernel=\"radial\")     \n",
    "par(mar=c(2.1, 2.1, .1, .1))\n",
    "options(repr.plot.width=2, repr.plot.height=2)\n",
    "plot(tune.svm(Coro~.,data=datapp,cost=c(.5,1,1.25,1.5,1.75,2)),main=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(predict(res.svm,datest,type=\"class\"),datest[,14]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Toutes les variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res.svm=svm(Coro~.,data=datapp,cost=0.5,kernel=\"radial\")     \n",
    "table(predict(res.svm,datest,type=\"class\"),datest[,14])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Composantes principales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2.svm=svm(Coro~.,data=datapp[,c(14,21:29)],cost=0.5,kernel=\"radial\")     \n",
    "table(predict(res2.svm,datest,type=\"class\"),datest[,14])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Quel est le paramètre `cost`? Commenter les résultats.\n",
    "### 2.5 [*K* plus proches voisins](http://wikistat.fr/pdf/st-m-app-add.pdf)\n",
    "**Q** Quelle contrainte pour cette méthode sur le choix des variables? Commenter les résultats (choix de *k*, qualité)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(class)\n",
    "options(repr.plot.width=2.5, repr.plot.height=2.5)\n",
    "par(mar=c(2.1, 2.1, .1, .1))\n",
    "plot(tune.knn(as.matrix(datapp[,c(1,4,5,8,10,21:28)]),as.factor(datapp[,c(14)]),k=2:20),main=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.knn=knn(datapp[,c(1,4,5,8,10,21:28)],datest[,c(1,4,5,8,10,21:28)],datapp[,c(14)],k=12,prob=T)\n",
    "table(pred.knn,datest[,14])  #15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 [Forêts aléatoires](http://wikistat.fr/pdf/st-m-app-agreg.pdf)\n",
    "\n",
    "#### Variables initiales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "library(randomForest)\n",
    "xapp=datapp[,-c(14,21:29)];yapp=datapp[,14];xtest=datest[,-c(14,21:29)];ytest=datest[,14]\n",
    "res.rf=randomForest(x=xapp, y=yapp, xtest=xtest, ytest=ytest, mtry=2,do.trace=50,\n",
    "                    importance=TRUE)\n",
    "sort(res.rf$importance[,3],decreasing=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Quel paramètres faudrait-il optimiser? A quoi sert `importance=TRUE` dans la fonction de cette méthode? Comment en interpréter le résultat?\n",
    "#### Toutes les variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xapp=datapp[,-14];yapp=datapp[,14];xtest=datest[,-14];ytest=datest[,14]\n",
    "res.rf=randomForest(x=xapp, y=yapp, xtest=xtest, ytest=ytest, mtry=2,do.trace=50,importance=TRUE)\n",
    "sort(res.rf$importance[,3],decreasing=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Composantes principales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xapp=datapp[,c(21:29)];yapp=datapp[,14];xtest=datest[,c(21:29)];ytest=datest[,14]\n",
    "res2.rf=randomForest(x=xapp, y=yapp, xtest=xtest, ytest=ytest, mtry=2,do.trace=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Que signifie OOB ? Comparer les qualité de prévision.\n",
    "### 2.7 [Gradient boosting](http://wikistat.fr/pdf/st-m-app-agreg.pdf)\n",
    "Cette implémentation inclut une optimisation par validation croisée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables initiales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(gbm)\n",
    "boost=gbm(as.numeric(datapp$Coro)-1~.,\n",
    "          data=datapp[,-c(21:28)],distribution=\"adaboost\",\n",
    "          n.trees=500, cv.folds=10,n.minobsinnode = 5,\n",
    "          shrinkage=0.01,verbose=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=3, repr.plot.height=3)\n",
    "par(mar=c(2.1, 2.1, .1, .1))\n",
    "best.iter=gbm.perf(boost,method=\"cv\")\n",
    "best.iter # 381\n",
    "pred.boost=predict(boost,newdata=datest,n.trees=best.iter)\n",
    "table(as.factor(sign(pred.boost)),datest[,14]) #19\n",
    "mean(sign(pred.boost) != (2*as.numeric(datest[,14])-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Comment ce graphe est-il obtenu? Quelle interprétation en tirer?\n",
    "#### Toutes les variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost=gbm(as.numeric(datapp$Coro)-1~.,data=datapp,distribution=\"adaboost\",\n",
    "          n.trees=500, cv.folds=10,n.minobsinnode = 5,shrinkage=0.01,verbose=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=3, repr.plot.height=3)\n",
    "par(mar=c(2.1, 2.1, .1, .1))\n",
    "best.iter=gbm.perf(boost,method=\"cv\")\n",
    "best.iter # 381\n",
    "pred.boost=predict(boost,newdata=datest,n.trees=best.iter)\n",
    "table(as.factor(sign(pred.boost)),datest[,14]) #19\n",
    "mean(sign(pred.boost) != (2*as.numeric(datest[,14])-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 Comparaison des [courbes ROC](http://wikistat.fr/pdf/st-m-app-risque.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "library(ROCR)\n",
    "roclogit=predict(res.log.step,newdata=datest,type=\"response\")\n",
    "predlogit=prediction(roclogit,datest[,14])\n",
    "perflogit=performance(predlogit,\"tpr\",\"fpr\")\n",
    "\n",
    "prob=attr(pred.knn,\"prob\")\n",
    "prob <- ifelse(pred.knn == \"CoA\", 1-prob, prob)\n",
    "\n",
    "predknn=prediction(prob,datest[,14])\n",
    "perfknn=performance(predknn,\"tpr\",\"fpr\")\n",
    "\n",
    "roctree=predict(res.tree,newdata=datest,type=\"prob\")[,2]\n",
    "predtree=prediction(roctree,datest[,14])\n",
    "perftree=performance(predtree,\"tpr\",\"fpr\")\n",
    "\n",
    "rocrn=predict(res.net,datest)\n",
    "predrn=prediction(rocrn,datest[,14])\n",
    "perfrn=performance(predrn,\"tpr\",\"fpr\")\n",
    "\n",
    "res.svm=svm(Coro~.,data=datapp[,c(14,20:28)],cost=3,kernel=\"radial\",probability=T)\n",
    "\n",
    "rocsvm=predict(res.svm,datest,probability=T)\n",
    "predsvm=prediction(attr(rocsvm,\"probabilities\")[,2],datest[,14])\n",
    "perfsvm=performance(predsvm,\"tpr\",\"fpr\")\n",
    "\n",
    "rocrf=res.rf$test$vote[,2]\n",
    "predrf=prediction(rocrf,datest[,14])\n",
    "perfrf=performance(predrf,\"tpr\",\"fpr\")\n",
    "\n",
    "predboost=prediction(pred.boost,datest[,14])\n",
    "perfboost=performance(predboost,\"tpr\",\"fpr\")\n",
    "\n",
    "\n",
    "options(repr.plot.width=4, repr.plot.height=3)\n",
    "par(mar=c(2.1, 2.1, .1, .1))\n",
    "palette(\"default\")\n",
    "plot(perflogit,col=1,lwd=2)\n",
    "plot(perfknn,col=2,lwd=3,add=T)\n",
    "plot(perftree,col=3,lwd=2,add=T)\n",
    "plot(perfrn,col=4,lwd=2,add=T)\n",
    "plot(perfsvm,col=5,lwd=2,add=T)\n",
    "plot(perfboost,col=6,lwd=2,add=TRUE)\n",
    "plot(perfrf,col=7,lwd=2,add=T,)\n",
    "\n",
    "legend(\"bottomright\",legend=c(\"logit\",\"knn\",\"rpart\",\"nnet\",\"svm\",\"gbm\",\"rf\"),\n",
    "       y.intersp=2,col=c(1:7),lty=1,lwd=2,text.width=0.15,ncol=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** A la vue de ce graphique, quelles méthodes abandonner à ce niveau? Pourquoi? Que dire de façon générale sur le choix de la meilleure stratégie pour déterminer le paquet de variables à utiliser? Distinguer selon l'objectif de prévision ou d'interprétation. \n",
    "\n",
    "La suite dépend des choix qui sont opérés en privilégiant la pévision \"brute\".\n",
    "## 3 Automatisation des optimisations\n",
    "La librairie `caret` permet d'automatiser les valeurs des paramètres de complexité des modèles pour chaque méthodes. Les échantillons apprentissage et test sont normalisés. \n",
    "\n",
    "**Q** Que signifie le paramètre `tunelength` de la fonction `train` de cette librairie?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(caret)\n",
    "# Extraction des échantillons\n",
    "trainDescr=datapp[,-14]\n",
    "testDescr=datest[,-14]\n",
    "trainY=datapp[,14]\n",
    "testY=datest[,14]\n",
    "\n",
    "# Normalisation\n",
    "xTrans=preProcess(trainDescr)\n",
    "trainDescr=predict(xTrans,trainDescr)\n",
    "testDescr=predict(xTrans,testDescr)\n",
    "# Choix de la validation croisée\n",
    "cvControl=trainControl(method=\"cv\",number=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Régression logistique\n",
    "L'option `tunelength` est inutile. L'algorithme opère une sélection de variables par algorithme `forward` minimisant l'AIC.\n",
    "\n",
    "**Q** POurqupoi ré-exécuter la commande `set.seed` avant l'optimisation du ou des paramètres pour chaque méthode?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(2)\n",
    "rlogFit = train(trainDescr, trainY,method = \"glmStepAIC\", tuneLength = 8, trControl = cvControl)\n",
    "rlogFit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Forêts aléatoires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(2)\n",
    "rfFit = train(trainDescr, trainY,method = \"rf\", tuneLength = 8,trControl = cvControl)\n",
    "rfFit\n",
    "options(repr.plot.width=3, repr.plot.height=3)\n",
    "par(mar=c(2.1, 2.1, .1, .1))\n",
    "plot(rfFit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 *Gradient boosting*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(2)\n",
    "gbmFit = train(trainDescr, trainY,method = \"gbm\", tuneLength = 8, \n",
    "               trControl = cvControl,verbose=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbmFit commande trop bavarde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=4, repr.plot.height=4)\n",
    "par(mar=c(2.1, 2.1, .1, .1))\n",
    "plot(gbmFit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Comment interpréter ce graphique?\n",
    "### 3.3 Séparateur à vaste marge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(2)\n",
    "svmgFit = train(trainDescr[,c(1,4,5,8,10,20:28)], trainY,method = \"svmRadial\", tuneLength = 8,trControl = cvControl)\n",
    "svmgFit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=3, repr.plot.height=3)\n",
    "par(mar=c(2.1, 2.1, .1, .1))\n",
    "plot(svmgFit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Réseau de neurones\n",
    "**Q** Quel autre paramètre permettrait de faire varier et prendre en compte l'implémentation du perceptron dans la librairie *Scikit-learn* de Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(2)\n",
    "nnetFit = train(trainDescr, trainY,method = \"nnet\", tuneLength = 6,trControl = cvControl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nnetFit # commande trop bavarde "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(nnetFit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 [Validation croisée](http://wikistat.fr/pdf/st-m-app-risque.pdf) *Monte Carlo*\n",
    "**Q** Que met en oeuvre cette procédure de validation croisée *Monte Carlo* (fonction `pred.autom`) ? Pourquoi?\n",
    "\n",
    "Attention, exécuter au préalable la fonction `pred.autom` définie en annexe à la fin de ce calepin.\n",
    "### 4.1 Base avec toutes les variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=c(\"gbm\",\"rf\",\"nnet\")\n",
    "noptim=c(6,6,6)\n",
    "Niter=30 ; Init=3\n",
    "predH=pred.autom(trainDescr, trainY,methodes=models,N=Niter,xinit=Init,size=noptim,type=\"prob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des taux de bien classés\n",
    "obs=predH$obs\n",
    "prevH=predH$pred\n",
    "resH=lapply(prevH,function(x)apply((x>0.5)==(obs==1),2,mean))\n",
    "# Moyennes des taux de bien classés par méthode\n",
    "lapply(resH,mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distributions des taux de bien classés\n",
    "options(repr.plot.width=2.2, repr.plot.height=2.2)\n",
    "par(mar=c(2.1, 2.1, .1, .1))\n",
    "boxplot(data.frame(resH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predrocH=lapply(prevH,function(x)prediction(x,obs==1))\n",
    "perfrocH=lapply(predrocH,function(x)performance(x,\"tpr\",\"fpr\"))\n",
    "options(repr.plot.width=4, repr.plot.height=3)\n",
    "par(mar=c(2.1, 2.1, .1, .1))\n",
    "plot(perfrocH$gbm,col=1,lwd=3,avg=\"threshold\")\n",
    "plot(perfrocH$nnet,col=3,add=TRUE,lwd=3,avg=\"threshold\")\n",
    "plot(perfrocH$rf,col=2,add=TRUE,lwd=3,avg=\"threshold\",\n",
    "     print.cutoffs.at=c(0.1, 0.25, 0.5, 0.75, 0.9))\n",
    "legend(\"bottomright\",legend=c(\"gbm\",\"nnet\",\"rf\"),y.intersp=3,\n",
    "       col=c(1,3,2),lty=1,lwd=2,text.width=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Que signifient les valeurs présentes sur les courbes ROC? Quelle conclusion tirer de ce graphique en fonction du taux de faux positif acceptable?\n",
    "### Variables initiales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=c(\"gbm\",\"rf\")\n",
    "noptim=c(10,10)\n",
    "Niter=30 ; Init=3 \n",
    "predH2=pred.autom(trainDescr[,-c(20:28)], trainY,methodes=models,N=Niter,xinit=Init,size=noptim,type=\"prob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des taux de bien classés\n",
    "obs=predH2$obs\n",
    "prevH2=predH2$pred\n",
    "resH2=lapply(prevH2,function(x)apply((x>0.5)==(obs==1),2,mean))\n",
    "# Moyennes des taux de bien classés par méthode\n",
    "lapply(resH2,mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distributions des taux de bien classés\n",
    "options(repr.plot.width=2.2, repr.plot.height=2.2)\n",
    "par(mar=c(2.1, 2.1, .1, .1))\n",
    "boxplot(data.frame(resH2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predrocH2=lapply(prevH2,function(x)prediction(x,obs==1))\n",
    "perfrocH2=lapply(predrocH2,function(x)performance(x,\"tpr\",\"fpr\"))\n",
    "options(repr.plot.width=4, repr.plot.height=3)\n",
    "par(mar=c(2.1, 2.1, .1, .1))\n",
    "plot(perfrocH2$gbm,col=1,lwd=3,avg=\"threshold\")\n",
    "plot(perfrocH2$rf,col=2,add=TRUE,lwd=3,avg=\"threshold\",\n",
    "     print.cutoffs.at=c(0.1, 0.25, 0.5, 0.75, 0.9))\n",
    "legend(\"bottomright\",legend=c(\"gbm\",\"rf\"),y.intersp=3,\n",
    "       col=c(1,2),lty=1,lwd=2,text.width=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Q** Quelle méthode ? Quelle stratégie de choix de base de données finalement choisir? Les différences vous semble-t-il significatives?\n",
    "## 4 [*XGBoost*](http://wikistat.fr/pdf/st-m-app-agreg.pdf) \n",
    "Comme le boosting conduit à des résultats encourageants, la librairie xgboost, utilisée dans la plupart des concours de prévision (kaggle), est testée dans l'espoir de les améliorer encore.\n",
    "\n",
    "### 4.1 Utilisation élémentaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainD=as.matrix(data.frame(tab.disjonctif(trainDescr[,-c(1,4,5,8,10,20:28)]),trainDescr[,c(1,4,5,8,10,20:28)]))\n",
    "TestD=as.matrix(data.frame(tab.disjonctif(testDescr[,-c(1,4,5,8,10,20:28)]),testDescr[,c(1,4,5,8,10,20:28)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(xgboost)\n",
    "xbst = xgboost(data = TrainD, label = as.numeric(trainY)-1, max.depth = 2,\n",
    "               eta = 1, nround = 30, objective = \"binary:logistic\")\n",
    "pred = predict(xbst, as.matrix(TestD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = as.numeric(pred > 0.5)\n",
    "err = mean(as.numeric(pred > 0.5) == as.numeric(testY))\n",
    "print(paste(\"test-error=\", err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbst = xgboost(data = as.matrix(trainDescr[,20:28]), label = as.numeric(trainY)-1, max.depth = 2,\n",
    "               eta = 1, nround = 30, objective = \"binary:logistic\")\n",
    "pred = predict(xbst, as.matrix(testDescr[,20:28]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = mean(as.numeric(pred > 0.5) == as.numeric(testY))\n",
    "print(paste(\"test-error=\", err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Optimisation des paramètres\n",
    "Le principal souci de cette librairie est lié au nombre de paramètres qui peuvent être optimisés. La librairie `caret` est utilisée pour facilité cette optimisation en première approche. Le calcul est long et d'autres moyens (*e.g.* GPU) seraient nécessaires pour espérer optimiser les valeurs de tous les paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(xgboost)\n",
    "set.seed(2)\n",
    "xgbmFit = train(as.matrix(TrainD), trainY,method = \"xgbTree\",tuneLength = 4,trControl = cvControl,verbose=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbmFit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Tuning parameter 'gamma' was held constant at a value of 0\n",
    "    Tuning parameter 'min_child_weight' was held constant at a value of 1\n",
    "    Accuracy was used to select the optimal model using  the largest value.\n",
    "    The final values used for the model were nrounds = 50, max_depth = 1, \n",
    "    eta = 0.3, gamma = 0, colsample_bytree = 0.8, min_child_weight = 1 and \n",
    "    subsample  = 0.5.  \n",
    "**Q** Ci-dessus la synthèse de résultats fournis par l'exécution de la commande `train` de `caret`. Que retenir de cette implémentation du boosting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=5, repr.plot.height=5)\n",
    "par(mar=c(2.1, 2.1, .1, .1))\n",
    "plot(xgbmFit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Automatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models=c(\"xgbTree\")\n",
    "noptim=c(4)\n",
    "Niter=30 ; Init=3 \n",
    "predH3=pred.autom(TrainD,trainY,methodes=models,N=Niter,xinit=Init,size=noptim,type=\"prob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des taux de bien classés\n",
    "obs=predH3$obs\n",
    "prevH3=predH3$pred\n",
    "resH3=lapply(prevH3,function(x)apply((x>0.5)==(obs==1),2,mean))\n",
    "# Moyennes des taux de bien classés par méthode\n",
    "lapply(data.frame(resH2,resH3),mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distributions des taux de bien classés\n",
    "options(repr.plot.width=2.2, repr.plot.height=2.2)\n",
    "par(mar=c(2.1, 2.1, .1, .1))\n",
    "boxplot(data.frame(resH2,resH3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predrocH3=lapply(prevH3,function(x)prediction(x,obs==1))\n",
    "perfrocH3=lapply(predrocH3,function(x)performance(x,\"tpr\",\"fpr\"))\n",
    "options(repr.plot.width=4, repr.plot.height=3)\n",
    "par(mar=c(2.1, 2.1, .1, .1))\n",
    "plot(perfrocH3$xgbTree,col=1,lwd=3,avg=\"threshold\")\n",
    "plot(perfrocH2$gbm,col=3,add=TRUE,lwd=3,avg=\"threshold\")\n",
    "plot(perfrocH2$rf,col=2,add=TRUE,lwd=3,avg=\"threshold\",\n",
    "     print.cutoffs.at=c(0.1, 0.25, 0.5, 0.75, 0.9))\n",
    "legend(\"bottomright\",legend=c(\"xgboost\",\"gbm\",\"rf\"),y.intersp=3,\n",
    "       col=c(1,3,2),lty=1,lwd=2,text.width=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Q** Commenter ces derniers résultats\n",
    "## Annexe: fonction de validation croisée *Monte Carlo*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred.autom=function(X,Y,p=1/2,methodes=c(\"knn\",\n",
    "   \"rf\"),size=c(10,2),xinit=11,N=10,typerr=\"cv\",\n",
    "   number=4,type=\"raw\")\n",
    "# Fonction de prévision de N échantillons tests\n",
    "# par une liste de méthodes de régression \n",
    "# ou classification (uniquement 2 classes)\n",
    "# Optimisation des paramètres par validation \n",
    "# croisée (défaut) ou bootstrap ou... (cf. caret)\n",
    "# X : matrice ou frame des variables explicatives\n",
    "# Y : variable cible quantitative ou qualitative \n",
    "# p : proportion entre apprentissage et test\n",
    "# methodes : liste des méthodes de rdiscrimination\n",
    "# size : e grille des paramètres à optimiser\n",
    "# xinit : générateur de nombres aléatoires\n",
    "# N : nombre de réplications apprentissage / test\n",
    "# typerr : \"cv\" ou \"boo\" ou \"oob\"\n",
    "# number : nombre de répétitions CV ou bootstrap\n",
    "# pred : liste des matrices de prévision\n",
    "{\n",
    "# type d'erreur\n",
    "Control=trainControl(method=typerr,number=number)\n",
    "# initialisation du générateur \n",
    "set.seed(xinit)\n",
    "# liste de matrices stockant les prévisions\n",
    "# une par méthode, une ligne par observation, \n",
    "# une colonne par échantillon test\n",
    "inTrain=createDataPartition(Y,p=p,list=FALSE)\n",
    "ntest=length(Y[-inTrain])\n",
    "pred=vector(\"list\",length(methodes))\n",
    "names(pred)=methodes\n",
    "pred=lapply(pred,function(x)x=matrix(0,\n",
    "   nrow=ntest,ncol=N))\n",
    "# variable cible des échantillons test\n",
    "obs=matrix(0,ntest,N)\n",
    "\n",
    "set.seed(xinit)\n",
    "# N itérations, une par échantillon test\n",
    "for(i in 1:N)  \n",
    "{\n",
    "# indices de l'échantillon d'apprentissage \n",
    "inTrain=createDataPartition(Y,p=p,list=FALSE)\n",
    "# Extraction des échantillons\n",
    "trainDescr=X[inTrain,]\n",
    "testDescr=X[-inTrain,]\n",
    "trainY=Y[inTrain]\n",
    "testY=Y[-inTrain]\n",
    "# stockage des observés de testY\n",
    "obs[,i]=testY\n",
    "# centrage et réduction des variables\n",
    "xTrans=preProcess(trainDescr)\n",
    "trainDescr=predict(xTrans,trainDescr)\n",
    "testDescr=predict(xTrans,testDescr)\n",
    "# estimation et optimisation des modèles \n",
    "# pour chaque méthode de la liste\n",
    "for(j in 1:length(methodes))\n",
    "{\n",
    "# modélisation \n",
    "modFit = train(trainDescr, trainY,\n",
    "   method = methodes[j], tuneLength = size[j],\n",
    "   trControl = Control)\n",
    "# prévisions de l'échantillon test\n",
    "if (type==\"prob\")  pred[[j]][,i]=predict(modFit,\n",
    "    newdata = testDescr,type=type)[,1]\n",
    "else pred[[j]][,i]=predict(modFit, \n",
    "   newdata = testDescr)\n",
    "}}\n",
    "list(pred=pred,obs=obs) # résultats\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
